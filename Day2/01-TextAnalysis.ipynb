{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f42023e-9c42-4fab-9480-c06415ec3211",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "Part 1: Basic text analysis\n",
    "\n",
    "Part 2: Cleaning and normalization\n",
    "\n",
    "Ideas for complex/advanced applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450aca1-4ddc-4b71-bd15-9d9139d3709e",
   "metadata": {
    "raw_mimetype": "pdf",
    "tags": []
   },
   "source": [
    "### Part 1: Basic Text Analysis \n",
    "\n",
    "NLTK (Natural Language Toolkit): \n",
    "\n",
    "A python library with functions specifically designed to analyze natural (not-computer) language.\n",
    "\n",
    "NLTK needs to be imported in any python script that uses it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d0961-d4b6-4e10-bfe7-2786eb4d5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39457a47-ee99-4886-a9ee-654a79c4892b",
   "metadata": {},
   "source": [
    "NLTK comes with two built-in texts, *Moby Dick* and *Sense and Sensibility.* Note the assumptions about how NLTK will be used: novels, long, canonical..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c76f42-681b-4458-9f22-464e6d872a29",
   "metadata": {},
   "source": [
    "#### **NLTK functions: Concordance()**\n",
    "\n",
    "- Called on a Text object and takes a string (a sequence of characters) as an argument\n",
    "\n",
    "- text_variable.condordance(string_arg) \n",
    "\n",
    "- Calling condordance(\"word\") returns the words that surround “word” in different sentences, helping us to get a glimpse of the contexts in which the word shows up. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32717810-57c2-4c25-96d8-20d1d3a39039",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = \"https://raw.githubusercontent.com/ucla/ca-dhri/main/Day2/Liberator91901.txt\"\n",
    "\n",
    "file = urlopen(my_url)\n",
    "liberator_raw = file.read()\n",
    "liberator_txt = liberator_raw.decode()\n",
    "txt_tokens = nltk.word_tokenize(liberator_txt)\n",
    "liberator = nltk.Text(txt_tokens)\n",
    "\n",
    "#let's make sure we created a text object\n",
    "liberator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c4f08-6a74-4e17-94cb-71d7e503985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call concordance on the word \"law\"\n",
    "liberator.concordance(\"law\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2157c4-bca7-470f-af3c-3a9974685c52",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **NLTK functions: Similar()**\n",
    "\n",
    "-text.similar(string_arg)\n",
    "\n",
    "-Like concordance, similar will find the contexts of the string variable it is given, but it can also compare the content of these contexts to all other words, looking for words that are used in similar contexts to the given argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456020e1-7f2f-47e3-b48f-4e2a7d5ca237",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.similar(\"law\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3461ce7-fcc8-4ec2-95f7-5ceeb376002b",
   "metadata": {},
   "source": [
    "#### **NLTK functions: dispersion plot**\n",
    "\n",
    "-text.dispersion_plot(list_arg)\n",
    "\n",
    "-Takes a list of strings as input (not a single string!) and outputs a graph of the instances where each word appears. If you want to make a plot for one string, pass the function a one-object list [“example”]\n",
    "\n",
    "-Note: dispersion_plot() is helpful for seeing how language changes over time or over narrative arcs. It might be more useful on a large collection of newspapers over time than on a single newspaper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409785c-b4cd-4cf5-929d-1d7c6433e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b89493-ae7a-44a4-981e-5404fa28b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\",\"furniture\",\"Angeles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98463815-a2f8-4533-9e13-7618098bf3b8",
   "metadata": {},
   "source": [
    "#### **NLTK functions: count()**\n",
    "\n",
    "-Takes a word as an argument and returns a count of each instance of that word in a text. \n",
    "\n",
    "-It is case sensitive (we will address cases in data cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4ec46-2c37-4b8e-a14c-8779b3966177",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.count(\"Angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3993e4-c61f-4aa9-ba42-df71bfafc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b2bd0-c2f5-4c7a-bb3b-3b6e829c9f19",
   "metadata": {},
   "source": [
    "### Practice in Breakout Rooms\n",
    "\n",
    "Can you think of how we could generate a concordance that would allow us to extract addresses from the text? What might we do with that information?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacef38-7fa7-4ab9-b0ac-f17675fb17ab",
   "metadata": {},
   "source": [
    "#### **Python operations on NLTK objects: len(), set()**\n",
    "\n",
    "So far, we have been using the built-in NLTK corpus to analyze our text object. We can also use regular python expressions on it:\n",
    "\n",
    "**len(text_object)** returns the length of the nltk object, that is, the number of words in the text. In a pre-cleaning text, this will include punctuation and metadata. \n",
    "\n",
    "**set(text_object)** creates a set (a list without duplicates) of all the unique words \n",
    "\n",
    "**len(set(text_object)** returns — you guessed it — the length of the set of unique words, ie, the number of unique words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825651c-82a8-48b1-8b72-40bea27c1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(liberator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d9d04-260f-497f-911b-a547af9b6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(liberator)\n",
    "sorted(set(liberator))[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f4e89-e499-4308-bf1b-7972582f725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(liberator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efc3c7-2b8b-43a7-98a5-38c6e5ee525e",
   "metadata": {},
   "source": [
    "### Part 2: Cleaning and Normalizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb4c67-20e1-4fa2-83df-a67d506a5b82",
   "metadata": {},
   "source": [
    "#### **Removing capitalization and punctuation**\n",
    "\n",
    "Type vs. token: \n",
    "- angeles vs. Angeles vs. ANGELES are distinct types\n",
    "    \n",
    "- A token is an instance of a type\n",
    "\n",
    "- nltk.count(“angeles”) counts the number of tokens of that type\n",
    "\n",
    "If the distinction between cases isn't important in your analysis, making all values of a text lowercase can be useful.\n",
    "\n",
    "So we'll start normalizing the text by making all words lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a85f-6829-43d7-a4a6-c8cb49dbc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase = [word.lower() for word in liberator] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303606b-852c-484e-9bf4-c6c48377b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752ba7f-db75-487e-8c4c-dd9997ce45eb",
   "metadata": {},
   "source": [
    "#### **Remove all punctuation**\n",
    "\n",
    "Lets run this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152f270-eb4c-4a0c-b654-bf52c9436d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_lowercase_textonly = [word.lower() for word in liberator if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c91ca-8ae0-4792-b4cd-b7ed9ae5977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What did we just do, though?\n",
    "#liberator_lowercase_textonly = [word.lower() for word in liberator if word.isalpha()] is shorthand for this function\n",
    "\n",
    "liberator_lowercase_textonly = []\t\t\t\t#define an empty list called liberator_lowercase_only\n",
    "\n",
    "for w in liberator:\t\t\t\t\t        #For each word (\"w\") in our existing text object \n",
    "\n",
    "\tif w.isalpha():\t\t\t\t        #if the word (“w”) is letters (not punctuation)\n",
    "        \n",
    "\t\tliberator_lowercase_textonly.append(w.lower())  \t#make it lowercase and add to our new list\n",
    "\n",
    "        #if the word is not alpha, the for loop will move on to the next word \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42a159-0b2f-49bf-9c08-22f56073bcea",
   "metadata": {},
   "source": [
    "TIP: be smart about your variable names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6b1d7-2222-4cd8-8e7b-f27d1aef27f8",
   "metadata": {},
   "source": [
    "#### **Removing stop words**\n",
    "\n",
    "- (\"the,\" \"an,\" \"a,\" etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc710393-fc20-4b0a-ae46-fa36845136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a predefined list of stopwords, how nice!\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#note, stopwords' type isn't a List, it's a WordListCorpusReader\n",
    "print(type(stopwords))\n",
    "\n",
    "#if we want a \"real\" list, we need to call the words attribute\n",
    "print(type(stopwords.words()))\n",
    "      \n",
    "#here's what we have:\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cb1fd-3870-45c5-ab73-596227d8ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of stopwords in our text\n",
    "\n",
    "#make sure you import stopwords somewhere in the script before you call it\n",
    "liberator_sans_stops = []\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "#define a new list\n",
    "for word in liberator_lowercase_textonly:\t\t\t\t#for each word in our cleaner list,\n",
    "    if word not in stops:\t                        #if that word isn’t in the list of stopwords,\n",
    "        liberator_sans_stops.append(word)\t\t        #add it to our new list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901649d8-4b60-4a82-94b2-258902fbcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#did it work?\n",
    "liberator_sans_stops.count(\"angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31f0db-c436-4c0e-b20f-9d37c0702025",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_sans_stops.count(\"of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76395b3-5e02-4326-8f5d-29b52dbf01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_sans_stops.count(\"after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c43b5-c978-410d-8b95-601bf8b17be9",
   "metadata": {},
   "source": [
    "#### **Lemmatizing words**\n",
    "\n",
    "- Lemmatization shrinks words to their grammatical root\n",
    "    - example, cats ⭢ cat and walked ⭢ walk\n",
    "  \n",
    "- This gets complicated in the case of men ⭢ man and sang ⭢ sing \n",
    "\n",
    "- Lemmatization looks up a word in a reference dictionary and finds the appropriate root (though this still is not entirely accurate and takes a long time, since each word must be looked up in a reference)\n",
    "\n",
    "- NLTK comes with pre-built stemmers and lemmatizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a1a66-3eab-42c8-b329-ffb73f1a9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\t\n",
    "\n",
    "#create an instance of it for our function\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\t\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize(\"children\"))\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\"))\n",
    "\n",
    "#for a word like “better,” need to specify grammatical function\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\", pos='a'))\n",
    "print(wordnet_lemmatizer.lemmatize(\"better\", pos='n'))\n",
    "\n",
    "#Parts of Speech\n",
    "#ADJ, ADJ_SAT, ADV, NOUN, VERB = \"a\", \"s\", \"r\", \"n\", \"v\"\n",
    "\n",
    "liberator_lemma = []\n",
    "for word in liberator_sans_stops:\n",
    "    word_lem = wordnet_lemmatizer.lemmatize(word)\n",
    "    liberator_lemma.append(word_lem)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bdc5fd-7a63-4179-ba85-7da45dec7d2d",
   "metadata": {},
   "source": [
    "### Part 3: Basic text analysis with our clean text\n",
    "\n",
    "Because we've lemmatized our text, the results of functions like concordance, similar, and count will change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca615c-797d-424a-a37c-9ec628fcc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to make our clean text an NLTK object to use the functions\n",
    "liberator_clean = nltk.Text(liberator_lemma)\n",
    "\n",
    "liberator_clean.concordance('law')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be138a-b5c7-4c60-9376-196ecf4a05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf20d05-0a50-4e66-9171-c65fc614e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca651f-ad38-4b2b-ab51-bbf82c4524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"anarchist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feab4c3-5a4a-4c90-bdce-4660c881c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.concordance(\"lawless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ad90d-d5ef-44aa-a1cc-201c3fb064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de2aec-771d-4f82-ae40-b58dec2d367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.similar(\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617aa5a-4e9d-48ef-9143-cb6dd35a7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator_clean.dispersion_plot([\"law\",\"america\",\"anarchist\",\"assassin\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba6cfb-4ac9-4882-9bea-3dc3f941bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "liberator.dispersion_plot([\"law\",\"America\",\"anarchist\",\"assassin\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f06dc-e03b-4f47-8008-b823516b736d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
